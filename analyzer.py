# analyzer.py
# FINAL COMPLETE & ROBUST HYBRID VERSION: Corrected all scope and caching errors.

import streamlit as st
import pandas as pd
import os
import re
from io import BytesIO
import requests
import time
from dotenv import load_dotenv

import sqlalchemy as db
from sqlalchemy.orm import sessionmaker, declarative_base, relationship
from sqlalchemy import Column, Integer, String, Text, ForeignKey

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser

# --- Global Setup (runs once) ---
st.set_page_config(layout="wide", page_title="×× ×ª×— ×“×•×—×•×ª ×¤×™× × ×¡×™×™×", page_icon="ğŸ¤–")
st.markdown("""<style>.stApp { direction: rtl; }</style>""", unsafe_allow_html=True)

load_dotenv()
IS_CLOUD = os.environ.get('STREAMLIT_SERVER_RUNNING_IN_CLOUD', 'false').lower() == 'true'
DEEPSEEK_API_KEY = st.secrets.get("DEEPSEEK_API_KEY") if IS_CLOUD else os.getenv("DEEPSEEK_API_KEY")

DB_URL = "https://huggingface.co/datasets/sagytb/reports/resolve/main/reports.sqlite?download=true"
LOCAL_DB_PATH = "reports.sqlite"

# --- Database Schema (Defined Globally) ---
Base = declarative_base()
class Document(Base):
    __tablename__ = 'documents'; id=Column(Integer, primary_key=True); filename=Column(String); company_name=Column(String); report_year=Column(Integer); full_text=Column(Text); language=Column(String); findings=relationship("Finding", back_populates="document"); auto_contacts=relationship("AutoContact", back_populates="document")
class Finding(Base):
    __tablename__ = 'findings'; id=Column(Integer, primary_key=True); document_id=Column(Integer, ForeignKey('documents.id')); category=Column(String); finding_text=Column(Text); document=relationship("Document", back_populates="findings")
class Contact(Base):
    __tablename__ = 'contacts'; id=Column(Integer, primary_key=True, autoincrement=True); first_name=Column(String); last_name=Column(String); company=Column(String); role=Column(String); phone=Column(String); email=Column(String)
class AutoContact(Base):
    __tablename__ = 'auto_contacts'; id=Column(Integer, primary_key=True, autoincrement=True); document_id=Column(Integer, ForeignKey('documents.id')); name=Column(String); role=Column(String); email=Column(String); phone=Column(String); document=relationship("Document", back_populates="auto_contacts")

# --- Database Connection Function (Cached) ---
@st.cache_resource
def get_db_session_factory():
    if IS_CLOUD and not os.path.exists(LOCAL_DB_PATH):
        info_message = st.info("××•×¨×™×“ ××ª ×‘×¡×™×¡ ×”× ×ª×•× ×™× ×-Hugging Face... â˜ï¸")
        try:
            r = requests.get(DB_URL, stream=True, timeout=120); r.raise_for_status()
            with open(LOCAL_DB_PATH, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192): f.write(chunk)
            info_message.success("×”×•×¨×“×ª ×‘×¡×™×¡ ×”× ×ª×•× ×™× ×”×•×©×œ××”!"); time.sleep(2); info_message.empty()
        except requests.exceptions.RequestException as e:
            info_message.error(f"×©×’×™××” ×‘×”×•×¨×“×ª ×‘×¡×™×¡ ×”× ×ª×•× ×™×: {e}"); return None
            
    if not os.path.exists(LOCAL_DB_PATH):
        st.error(f"×§×•×‘×¥ ×‘×¡×™×¡ ×”× ×ª×•× ×™× '{LOCAL_DB_PATH}' ×œ× × ××¦×. ×× × ×”×¨×¥ 'process_files.py'."); return None

    engine = db.create_engine(f'sqlite:///{LOCAL_DB_PATH}')
    Base.metadata.create_all(engine)
    return sessionmaker(bind=engine)

# --- Querying Functions (Now get the factory internally) ---
def to_excel(df: pd.DataFrame) -> bytes:
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
        for column in df:
            column_length = max(df[column].astype(str).map(len).max(), len(column)) + 2
            col_idx = df.columns.get_loc(column)
            writer.sheets['Sheet1'].set_column(col_idx, col_idx, column_length)
    return output.getvalue()

@st.cache_data(ttl=3600)
def get_available_years():
    Session = get_db_session_factory()
    if not Session: return []
    session = Session()
    try:
        years = session.query(Document.report_year).distinct().order_by(Document.report_year.desc()).all()
        return [y[0] for y in years if y[0] is not None]
    finally: session.close()

@st.cache_data(ttl=3600)
def get_predefined_reports(selected_years: list):
    Session = get_db_session_factory()
    if not selected_years or not Session: return {}
    session = Session(); reports = {}
    report_queries = {"× ×“×œ\"×Ÿ ×‘×™×©×¨××œ": "real_estate_israel", "×§×¨×§×¢×•×ª ×›××œ××™ ×‘×™×©×¨××œ": "land_inventory_israel", "× ×“×œ\"×Ÿ ×‘××¨×”\"×‘": "real_estate_usa", "× ×“×œ\"×Ÿ ×‘××™×¨×•×¤×”": "real_estate_europe", "××©×§×™×¢×•×ª ×‘×¡×˜××¨×˜××¤×™×": "startup_investments", "×—×‘×¨×•×ª ×‘×ª×—×•× ×”×× ×¨×’×™×”": "energy_sector", "×§× ×™×•× ×™× ××ª×•×›× × ×™×": "malls_planned", "××¨×›×–×™× ××¡×—×¨×™×™× ××ª×•×›× × ×™×": "commercial_centers_planned", "×©×›×•× ×•×ª ×—×“×©×•×ª ××ª×•×›× × ×•×ª": "new_neighborhoods", "××’×•×¨×™× ×•××¡×—×¨ ××©×•×œ×‘": "mixed_use_residential"}
    try:
        for name, category in report_queries.items():
            query = (session.query(Document.company_name, Document.report_year, Finding.finding_text, Document.filename).join(Finding).filter(Finding.category == category).filter(Document.report_year.in_(selected_years)))
            reports[name] = pd.read_sql(query.statement, session.bind)
    finally: session.close()
    return reports

@st.cache_data(ttl=3600)
def get_new_findings(year_to_check, base_year):
    Session = get_db_session_factory()
    if not Session: return pd.DataFrame(), pd.DataFrame()
    session = Session()
    try:
        query_new = (session.query(Document.company_name, Finding.finding_text, Finding.category).join(Finding).filter(Document.report_year == year_to_check))
        df_new = pd.read_sql(query_new.statement, session.bind)
        query_base = (session.query(Document.company_name, Finding.finding_text).join(Finding).filter(Document.report_year == base_year))
        df_base = pd.read_sql(query_base.statement, session.bind)
        if df_new.empty: return pd.DataFrame(), df_base.rename(columns={'company_name': '×©× ×—×‘×¨×”', 'finding_text': '×××¦×'})
        if df_base.empty: return df_new.rename(columns={'company_name': '×©× ×—×‘×¨×”', 'category': '×§×˜×’×•×¨×™×”', 'finding_text': '×××¦×'}), pd.DataFrame()
        df_new['key'] = df_new['company_name'] + df_new['finding_text']; df_base['key'] = df_base['company_name'] + df_base['finding_text']
        new_findings_df = df_new[~df_new['key'].isin(df_base['key'])]; removed_findings_df = df_base[~df_base['key'].isin(df_new['key'])]
        return new_findings_df.drop(columns=['key']), removed_findings_df.drop(columns=['key'])
    finally: session.close()

@st.cache_data(ttl=60)
def get_contacts_df(manual=True):
    Session = get_db_session_factory()
    if not Session: return pd.DataFrame()
    session = Session()
    try:
        if manual:
            query = session.query(Contact).statement; df = pd.read_sql(query, session.bind); return df.rename(columns={'id': '××–×”×”', 'first_name': '×©× ×¤×¨×˜×™', 'last_name': '×©× ××©×¤×—×”', 'company': '×—×‘×¨×”', 'role': '×ª×¤×§×™×“', 'phone': '×˜×œ×¤×•×Ÿ', 'email': '××™×™×œ'})
        else:
            query = (session.query(Document.company_name, AutoContact.name, AutoContact.role, AutoContact.email, AutoContact.phone, Document.filename).join(AutoContact)); df = pd.read_sql(query.statement, session.bind); return df.rename(columns={'company_name': '×©× ×—×‘×¨×” (×‘×“×•×—)', 'name': '×©× ××™×© ×§×©×¨', 'role': '×ª×¤×§×™×“', 'email': '××™×™×œ', 'phone': '×˜×œ×¤×•×Ÿ', 'filename': '×§×•×‘×¥ ××§×•×¨'})
    finally: session.close()

@st.cache_data(ttl=60)
def get_documents_for_editing():
    Session = get_db_session_factory()
    if not Session: return pd.DataFrame()
    session = Session()
    try:
        query = session.query(Document.id, Document.filename, Document.company_name).statement; df = pd.read_sql(query, session.bind)
        return df.rename(columns={'id': '××–×”×”', 'filename': '×©× ×§×•×‘×¥', 'company_name': '×©× ×—×‘×¨×” (× ×™×ª×Ÿ ×œ×¢×¨×™×›×”)'})
    finally: session.close()

def get_deepseek_llm(api_key):
    return ChatOpenAI(model="deepseek-chat", api_key=api_key, base_url="https://api.deepseek.com/v1", temperature=0)

def ai_asset_search(api_key, question: str, selected_years: list):
    Session = get_db_session_factory()
    if not Session: return "×©×’×™××”: ×œ× × ×™×ª×Ÿ ×œ×”×ª×—×‘×¨ ×œ×‘×¡×™×¡ ×”× ×ª×•× ×™×."
    session = Session()
    try:
        search_terms = re.findall(r'\b\w+\b', question); finding_filter = [Finding.finding_text.like(f'%{term}%') for term in search_terms]; candidate_findings = (session.query(Document.company_name, Document.filename, Finding.finding_text).join(Finding).filter(db.or_(Finding.category == 'real_estate_israel', Finding.category == 'land_inventory_israel'), Document.report_year.in_(selected_years), db.or_(*finding_filter)).limit(30).all())
        if not candidate_findings: return "×œ× × ××¦××• ×××¦××™× ×¨××©×•× ×™×™× ×”×ª×•×××™× ×œ×©××œ×ª×š ×‘×©× ×™× ×©× ×‘×—×¨×•."
        context = "\n\n".join(f"Company: {f.company_name}, File: {f.filename}\nFinding: {f.finding_text}" for f in candidate_findings); summarize_template = "Based *only* on the provided findings about Israeli real estate, answer the user's question. Create a Markdown table. User's Question: {question}. Findings: {context}. Final Answer (as a Markdown table in Hebrew):"; prompt = ChatPromptTemplate.from_template(summarize_template); chain = prompt | get_deepseek_llm(api_key) | StrOutputParser(); return chain.invoke({"question": question, "context": context})
    finally: session.close()

def parse_markdown_to_df(markdown_text):
    try:
        table_start = markdown_text.find('|');
        if table_start == -1: return None
        from io import StringIO
        cleaned = "\n".join([l.strip() for l in markdown_text[table_start:].strip().split('\n') if '|' in l and '---' not in l])
        df = pd.read_csv(StringIO(cleaned), sep='|', index_col=False).iloc[:, 1:-1]
        df.columns = [c.strip() for c in df.columns];
        if df.empty: return None
        return df
    except Exception: return None

# --- Main App Logic ---
def main():
    st.title("ğŸ¤– ×× ×ª×— ×“×•×—×•×ª ×¤×™× × ×¡×™×™×")
    if not DEEPSEEK_API_KEY: 
        st.error("××¤×ª×— API ×©×œ DeepSeek ×œ× ×”×•×’×“×¨."); 
        st.stop()

    Session_factory = get_db_session_factory()
    if not Session_factory:
        st.stop()

    available_years = get_available_years()
    if available_years:
        selected_years = st.sidebar.multiselect("×‘×—×¨ ×©× ×•×ª ×“×•×— ×œ×”×¦×’×”:", options=available_years, default=available_years)
        if not selected_years: st.sidebar.warning("×™×© ×œ×‘×—×•×¨ ×œ×¤×—×•×ª ×©× ×ª ×“×•×— ××—×ª."); st.stop()
    else:
        selected_years = []

    PAGES = {"ğŸ“Š ×“×•×—×•×ª ×¨××©×™×™×": "main_reports", "âœ¨ ××” ×—×“×©?": "whats_new", "ğŸ  ××™×ª×•×¨ × ×›×¡×™× ×‘×™×©×¨××œ": "asset_search", "ğŸ‘¥ ×× ×©×™ ×§×©×¨": "contacts_page", "ğŸ“ × ×™×”×•×œ ×•×¢×¨×™×›×ª × ×ª×•× ×™×": "data_management"}
    st.sidebar.title("× ×™×•×•×˜"); 
    selection = st.sidebar.radio("×‘×—×¨ ×¢××•×“:", list(PAGES.keys())); 
    page = PAGES[selection]
    
    if page == "main_reports":
        st.header(f"×“×•×—×•×ª ××¡×›××™× ×¢×‘×•×¨ ×”×©× ×™×: {', '.join(map(str, sorted(selected_years)))}")
        st.info("×”×“×•×—×•×ª ×œ×”×œ×Ÿ ××¦×™×’×™× ×××¦××™× ×©×—×•×œ×¦×• ××•×˜×•××˜×™×ª ××›×œ×œ ×”××¡××›×™×.")
        reports = get_predefined_reports(selected_years)
        for report_name, df in reports.items():
            with st.expander(f"**{report_name}** ({len(df)} ×××¦××™×)"):
                if not df.empty:
                    display_df = df.rename(columns={'company_name': '×©× ×—×‘×¨×”', 'report_year': '×©× ×ª ×“×•×—', 'finding_text': '×××¦×', 'filename': '×©× ×§×•×‘×¥'}); 
                    st.dataframe(display_df, use_container_width=True, hide_index=True); 
                    st.download_button(label=f"ğŸ“¥ ×™×™×¦× ××ª ×¨×©×™××ª '{report_name}' ×œ××§×¡×œ", data=to_excel(display_df), file_name=f"{report_name.replace('\"', '')}.xlsx", key=f"export_{report_name}")
                else: 
                    st.write("×œ× × ××¦××• ×××¦××™× ×‘×§×˜×’×•×¨×™×” ×–×• ×¢×‘×•×¨ ×”×©× ×™× ×©× ×‘×—×¨×•.")
    
    elif page == "whats_new":
        st.header("××” ×—×“×©? - ×”×©×•×•××” ×‘×™×Ÿ ×©× ×™×")
        if len(available_years) < 2: st.info("× ×“×¨×©×•×ª ×œ×¤×—×•×ª ×©×ª×™ ×©× ×•×ª × ×ª×•× ×™× ×›×“×™ ×œ×‘×¦×¢ ×”×©×•×•××”.")
        else:
            st.info("×›×œ×™ ×–×” ××¦×™×’ ×××¦××™× ×©×”×•×¤×™×¢×• ×‘×©× ×” ×”×—×“×©×” ××š ×œ× ×”×•×¤×™×¢×• ×‘×©× ×” ×”×™×©× ×”, ×•×××¦××™× ×©×”×•×¡×¨×•.")
            c1, c2 = st.columns(2); 
            compare_year = c1.selectbox("×”×¦×’ ×©×™× ×•×™×™× ××©× ×ª:", available_years, index=0); 
            base_year = c2.selectbox("×‘×”×©×•×•××” ×œ×©× ×ª:", available_years, index=1 if len(available_years)>1 else 0)
            if st.button("×‘×¦×¢ ×”×©×•×•××”"):
                if compare_year == base_year: st.warning("×™×© ×œ×‘×—×•×¨ ×©×ª×™ ×©× ×™× ×©×•× ×•×ª ×œ×”×©×•×•××”.")
                else:
                    with st.spinner(f"××©×•×•×” ××ª {compare_year} ××•×œ {base_year}..."):
                        new, removed = get_new_findings(compare_year, base_year)
                        st.subheader(f"×××¦××™× ×—×“×©×™× ×‘×©× ×ª {compare_year}"); 
                        st.dataframe(new.rename(columns={'company_name': '×©× ×—×‘×¨×”', 'category': '×§×˜×’×•×¨×™×”', 'finding_text': '×××¦×'}), use_container_width=True) if not new.empty else st.write("×œ× × ××¦××• ×××¦××™× ×—×“×©×™×.")
                        st.subheader(f"×××¦××™× ×©×”×•×¡×¨×• (×”×™×• ×‘-{base_year}, × ×¢×œ××• ×‘-{compare_year})"); 
                        st.dataframe(removed.rename(columns={'company_name': '×©× ×—×‘×¨×”', 'finding_text': '×××¦×'}), use_container_width=True) if not removed.empty else st.write("×œ× × ××¦××• ×××¦××™× ×©×”×•×¡×¨×•.")

    elif page == "asset_search":
        st.header("××™×ª×•×¨ × ×›×¡×™× ×‘×™×©×¨××œ")
        tab1, tab2 = st.tabs(["ğŸ’¬ ×©×™×—×” ×¢× AI", "ğŸ” ×—×™×¤×•×© ×¤×©×•×˜"])
        with tab1:
            st.info("×©××œ ×©××œ×” ×‘×©×¤×” ×—×•×¤×©×™×ª ×¢×œ × ×›×¡×™× ×‘×™×©×¨××œ. ×”-AI ×™×—×¤×© ×‘×××¦××™× ×”×¨×œ×•×•× ×˜×™×™× ×•×™×¡×›× ××ª ×”×ª×©×•×‘×”.")
            if "asset_messages" not in st.session_state: st.session_state.asset_messages = []
            for msg in st.session_state.asset_messages:
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
            if prompt := st.chat_input("×œ×“×•×’××”: ××™×œ×• ×—×‘×¨×•×ª ××—×–×™×§×•×ª ×§×¨×§×¢×•×ª ×‘×—×™×¤×”?"):
                st.session_state.asset_messages.append({"role": "user", "content": prompt}); st.rerun()
            if st.session_state.asset_messages and st.session_state.asset_messages[-1]["role"] == "user":
                with st.chat_message("assistant"):
                    with st.spinner("×—×•×©×‘..."):
                        response = ai_asset_search(st.session_state.asset_messages[-1]["content"], selected_years)
                        st.markdown(response); st.session_state.asset_messages.append({"role": "assistant", "content": response}); st.rerun()
        with tab2:
            st.info("×”×–×Ÿ ××•× ×— (×¢×™×¨, ×¨×—×•×‘, ×¡×•×’ × ×›×¡) ×œ×—×™×¤×•×© ××”×™×¨ ×‘×›×œ ×”×˜×§×¡×˜×™× ×©×œ ×”×“×•×—×•×ª.")
            keyword = st.text_input("×”×–×Ÿ ××•× ×— ×œ×—×™×¤×•×©:", key="keyword_search")
            if st.button("×—×¤×©", key="search_button"):
                if keyword:
                    with st.spinner("××—×¤×©..."):
                        session = Session_factory(); results = session.query(Document.company_name, Document.filename, Document.full_text).filter(Document.full_text.like(f'%{keyword}%'), Document.report_year.in_(selected_years)).limit(50).all(); session.close()
                        if results:
                            st.success(f"× ××¦××• {len(results)} ××¡××›×™× ×”××›×™×œ×™× ××ª ×”××•× ×— '{keyword}' ×‘×©× ×™× ×©× ×‘×—×¨×•:")
                            for doc in results:
                                try:
                                    safe_keyword = re.escape(keyword); match = re.search(safe_keyword, doc.full_text, re.IGNORECASE)
                                    if match:
                                        snippet = doc.full_text[max(0, match.start() - 80):match.end() + 80]
                                        highlighted_snippet = re.sub(f'({safe_keyword})', r'**\1**', snippet, flags=re.IGNORECASE)
                                        st.info(f"**×—×‘×¨×”:** {doc.company_name} | **×§×•×‘×¥:** {doc.filename}"); st.markdown(f'<div dir="rtl">...{highlighted_snippet}...</div>', unsafe_allow_html=True)
                                except Exception as e: st.warning(f"×œ× × ×™×ª×Ÿ ×”×™×” ×œ×”×¦×™×’ ×§×˜×¢ ××ª×•×š '{doc.filename}': {e}")
                        else: st.warning(f"×”××•× ×— '{keyword}' ×œ× × ××¦× ×‘××£ ××¡××š ×‘×©× ×™× ×©× ×‘×—×¨×•.")
                else: st.warning("×× × ×”×–×Ÿ ××•× ×— ×œ×—×™×¤×•×©.")
    
    elif page == "contacts_page":
        st.header("× ×™×”×•×œ ×× ×©×™ ×§×©×¨")
        st.subheader("×× ×©×™ ×§×©×¨ ×©×—×•×œ×¦×• ××•×˜×•××˜×™×ª ××”×“×•×—×•×ª")
        auto_contacts_df = get_contacts_df(manual=False)
        if not auto_contacts_df.empty:
            st.dataframe(auto_contacts_df, use_container_width=True, hide_index=True)
            st.download_button(label="ğŸ“¥ ×™×™×¦× ×¨×©×™××” ××•×˜×•××˜×™×ª ×œ××§×¡×œ", data=to_excel(auto_contacts_df), file_name="×× ×©×™_×§×©×¨_××•×˜×•××˜×™.xlsx")
        else: st.info("×œ× ×—×•×œ×¦×• ×× ×©×™ ×§×©×¨ ×‘××•×¤×Ÿ ××•×˜×•××˜×™ ××”××¡××›×™×.")
        st.markdown("---")
        if not IS_CLOUD:
            with st.form("contact_form", clear_on_submit=True):
                st.subheader("×”×•×¡×¤×ª ××™×© ×§×©×¨ ×™×“× ×™×ª")
                c1, c2 = st.columns(2); first_name = c1.text_input("×©× ×¤×¨×˜×™"); last_name = c2.text_input("×©× ××©×¤×—×”"); company = c1.text_input("×©× ×—×‘×¨×”"); role = c2.text_input("×ª×¤×§×™×“"); phone = c1.text_input("×˜×œ×¤×•×Ÿ"); email = c2.text_input("×›×ª×•×‘×ª ××™×™×œ")
                if st.form_submit_button("×©××•×¨ ××™×© ×§×©×¨"):
                    if not first_name or not last_name: st.error("×©× ×¤×¨×˜×™ ×•×©× ××©×¤×—×” ×”× ×©×“×•×ª ×—×•×‘×”.")
                    else:
                        session = Session_factory();
                        try:
                            new_contact = Contact(first_name=first_name, last_name=last_name, company=company, role=role, phone=phone, email=email)
                            session.add(new_contact); session.commit(); st.success(f"××™×© ×”×§×©×¨ '{first_name} {last_name}' × ×©××¨!"); st.cache_data.clear()
                        finally: session.close()
            st.markdown("---")
            st.subheader("×¨×©×™××ª ×× ×©×™ ×§×©×¨ (×™×“× ×™×ª)")
            contacts_df = get_contacts_df(manual=True)
            search_term = st.text_input("×—×¤×© ××™×© ×§×©×¨:")
            if search_term: contacts_df = contacts_df[contacts_df.apply(lambda row: search_term.lower() in ' '.join(row.astype(str)).lower(), axis=1)]
            if not contacts_df.empty:
                edited_df = st.data_editor(contacts_df, key="contacts_editor", use_container_width=True, hide_index=True, disabled=["××–×”×”"])
                st.download_button(label="ğŸ“¥ ×™×™×¦× ×¨×©×™××” ×™×“× ×™×ª ×œ××§×¡×œ", data=to_excel(edited_df.drop(columns=['××–×”×”'])), file_name="×× ×©×™_×§×©×¨_×™×“× ×™.xlsx")
                if not contacts_df.equals(edited_df):
                    session = Session_factory()
                    try:
                        changed_rows = pd.concat([contacts_df, edited_df]).drop_duplicates(keep=False)
                        for _, row in changed_rows.iterrows():
                            if row['××–×”×”'] in edited_df['××–×”×”'].values:
                                contact_to_update = session.query(Contact).filter_by(id=row['××–×”×”']).one()
                                contact_to_update.first_name, contact_to_update.last_name, contact_to_update.company, contact_to_update.role, contact_to_update.phone, contact_to_update.email = row['×©× ×¤×¨×˜×™'], row['×©× ××©×¤×—×”'], row['×—×‘×¨×”'], row['×ª×¤×§×™×“'], row['×˜×œ×¤×•×Ÿ'], row['××™×™×œ']
                        session.commit(); st.toast("×”×©×™× ×•×™×™× × ×©××¨×•!"); st.cache_data.clear(); st.rerun()
                    except Exception as e:
                        session.rollback(); st.error(f"×©×’×™××” ×‘×¢×“×›×•×Ÿ: {e}")
                    finally: session.close()
            else: st.info("×œ× × ××¦××• ×× ×©×™ ×§×©×¨." if search_term else "×¢×“×™×™×Ÿ ×œ× × ×•×¡×¤×• ×× ×©×™ ×§×©×¨.")
        else:
            st.info("× ×™×”×•×œ ×× ×©×™ ×§×©×¨ (×”×•×¡×¤×” ×•×¢×¨×™×›×”) ××¤×©×¨×™ ×¨×§ ×‘×’×¨×¡×” ×”××§×•××™×ª ×©×œ ×”××¤×œ×™×§×¦×™×”.")
            st.subheader("×¨×©×™××ª ×× ×©×™ ×§×©×¨ (×™×“× ×™×ª)")
            manual_contacts_df = get_contacts_df(manual=True)
            if not manual_contacts_df.empty:
                st.dataframe(manual_contacts_df.drop(columns=['××–×”×”']), use_container_width=True, hide_index=True)
                st.download_button(label="ğŸ“¥ ×™×™×¦× ×¨×©×™××” ×™×“× ×™×ª ×œ××§×¡×œ", data=to_excel(manual_contacts_df.drop(columns=['××–×”×”'])), file_name="×× ×©×™_×§×©×¨_×™×“× ×™.xlsx")
            else: st.info("×œ× ×”×•×¡×¤×• ×× ×©×™ ×§×©×¨ ×‘××•×¤×Ÿ ×™×“× ×™.")

    elif page == "data_management":
        st.header("× ×™×”×•×œ ×•×¢×¨×™×›×ª × ×ª×•× ×™×")
        if IS_CLOUD: st.warning("×¢×¨×™×›×ª × ×ª×•× ×™× ××¤×©×¨×™×ª ×¨×§ ×‘×’×¨×¡×” ×”××§×•××™×ª ×©×œ ×”××¤×œ×™×§×¦×™×”.")
        else:
            st.subheader("×¢×¨×™×›×ª ×©××•×ª ×—×‘×¨×•×ª")
            st.info("×›××Ÿ × ×™×ª×Ÿ ×œ×ª×§×Ÿ ××ª ×©××•×ª ×”×—×‘×¨×•×ª ×©×–×•×”×• ××•×˜×•××˜×™×ª. ×œ×—×¥ ×¢×œ ×ª× ×‘×˜×‘×œ×”, ×”×§×œ×“ ××ª ×”×©× ×”×—×“×© ×•×œ×—×¥ Enter. ×”×©×™× ×•×™ ×™×™×©××¨ ××•×˜×•××˜×™×ª.")
            docs_df = get_documents_for_editing()
            if not docs_df.empty:
                if 'original_docs' not in st.session_state or not st.session_state.original_docs.equals(docs_df):
                    st.session_state.original_docs = docs_df.copy()
                edited_df = st.data_editor(docs_df, key="docs_editor", use_container_width=True, hide_index=True, disabled=["××–×”×”", "×©× ×§×•×‘×¥"])
                if not st.session_state.original_docs.equals(edited_df):
                    session = Session_factory()
                    try:
                        diff = pd.concat([st.session_state.original_docs, edited_df]).drop_duplicates(keep=False)
                        for _, row in diff.iterrows():
                            if row['××–×”×”'] in edited_df['××–×”×”'].values:
                                new_name = edited_df.loc[edited_df['××–×”×”'] == row['××–×”×”'], '×©× ×—×‘×¨×” (× ×™×ª×Ÿ ×œ×¢×¨×™×›×”)'].iloc[0]
                                doc_to_update = session.query(Document).filter_by(id=row['××–×”×”']).one()
                                doc_to_update.company_name = new_name
                        session.commit(); st.toast("×”×©×™× ×•×™×™× × ×©××¨×•!", icon="âœ”ï¸"); st.cache_data.clear(); st.rerun()
                    except Exception as e:
                        session.rollback(); st.error(f"×©×’×™××” ×‘×¢×“×›×•×Ÿ ×©× ×”×—×‘×¨×”: {e}")
                    finally: session.close()
            else: st.info("××™×Ÿ ××¡××›×™× ×‘×‘×¡×™×¡ ×”× ×ª×•× ×™× ×œ×¢×¨×™×›×”.")

if __name__ == "__main__":
    main()
